%% LyX 2.1.4 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[oneside,spanish]{book}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}
\usepackage{float}
\usepackage{graphicx}

\makeatletter
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\newenvironment{lyxlist}[1]
{\begin{list}{}
{\settowidth{\labelwidth}{#1}
 \setlength{\leftmargin}{\labelwidth}
 \addtolength{\leftmargin}{\labelsep}
 \renewcommand{\makelabel}[1]{##1\hfil}}}
{\end{list}}

\makeatother

\usepackage{babel}
\addto\shorthandsspanish{\spanishdeactivate{~<>}}

\begin{document}

\chapter{Evaluación\label{chap:Evaluaci=0000F3n}}

En este capítulo se describe el procedimiento de evaluación que se
lleva a cabo y una descripción completa sobre los escenarios considerados
y cada uno de los dataset involucrados. También, se presentan los
resultados obtenidos junto con las inferencias y relaciones que se
han determinado entre las técnicas y el contexto en el que se aplican. 

El capítulo se organiza de la siguiente manera: en la sección \ref{sec:Metodolog=0000EDa-de-Evaluaci=0000F3n}
se detalla la metodología de evaluación propuesta para analizar la
eficacia de los modelos de predicción, en esta se incluye información
complementaria y particular que fue tomada en cuenta para llevar a
cabo la evaluación mediante sub-secciones individuales, de esta manera
se especifican, las métricas usadas, el formato de los resultados
obtenidos, la determinación empleada para la configuración de los
parámetros más fundamentales de cada técnica y las características
de los dispositivos móviles usados para las pruebas. 

En la sección \ref{sec:Escenarios} se presentan los escenarios de
estudio considerados, brindando una descripción detallada de los dataset
involucrados junto a gráficas y análisis sobre la distribución de
los datos, con el fin de comprender mejor el desempeño de las tecnicas
de regresion analizadas. Los modelos de predicción obtenidos son expuestos
en la sección \ref{sec:Resultados-y-discusi=0000F3n} desglosados
por escenario para analizar cómo impacta en el desempeño de las técnicas,
las particularidades de cada dominio. Finalmente en la sección \ref{sec:Conclusiones}
se obtienen las conclusiones del capítulo. 


\section{Metodología de Evaluación\label{sec:Metodolog=0000EDa-de-Evaluaci=0000F3n}}

Existen diversas formas que permiten evaluar la eficacia del clasificador.
La calidad de los modelos será evaluada a través de seis métricas
de regresión que representan de forma distinta el error de predicción.
Así mismo, para un análisis más profundo sobre las distintas técnicas
y su desempeño se usaron cuatro escenarios o contextos dispares entre
sí para determinar, de ser posible, las técnicas que mejor se adecuan
a un escenario (por su naturaleza), o por el contrario, no aplican
adecuadamente ante un escenario particular. 

Cada modelo es definido por una técnica \emph{X} (regresión lineal,
red neuronal, etc.) que se aplica para predecir una propiedad \emph{Y},
(tiempo de respuesta y precisión) de un componente \emph{Z}. Cada
uno de los contextos empleados incluyen tres o cuatro datasets, en
algunos casos para individualizar el análisis hacia los componentes
específicos, en otros, para separar las pruebas realizadas en móviles
distintos. 

En todo el conjunto de dataset, se añadió el tiempo de respuesta como
propiedad a predecir, y sólo en aquellos donde el contexto lo permitía
se incorporó como propiedad la optimalidad o precisión en el resultado
arrojado por el componente. 


\subsection{Métricas de evaluación\label{subsec:M=0000E9tricas-de-evaluaci=0000F3n}}

Tras construir una serie de modelos de regresión diferentes, existe
una gran cantidad de criterios por los cuales pueden ser evaluados
y comparados. Todos los indicadores comparan los valores reales con
sus estimaciones, pero lo hacen de una manera ligeramente diferente. 

\emph{\ac{MAE}} representa el promedio del error absoluto (diferencia
entre los valores predichos y los observados), e indica cuán grande
es el error que puede esperarse de la predicción. Al tratarse de una
métrica basada en el error medio puede subestimar el impacto de errores
grandes pero infrecuentes. Si el análisis se centra demasiado en la
media arrojará conclusiones precipitadas, por lo tanto para ajustar
errores grandes y raros, se calcula el error cuadrático medio (\ac{RMSE}).
Mediante la cuadratura de los errores en lugar de la media y luego
tomar la raíz cuadrada de la media, se llega a una medida del tamaño
del error que da más peso a los errores grandes e infrecuentes que
la media. 

La comparación entre las métricas \emph{\ac{RMSE} }y \emph{\ac{MAE}
}puede ser útil para determinar si un dataset contiene errores significativos
y poco frecuentes, cuanto mayor sea la diferencia entre ambos indicadores,
más inconsistente es el tamaño del error.

El coeficiente de correlación (\emph{CC}) es analizado en conjunto
con el indicador \emph{\ac{RMSE}} ya que existe una estrecha relación
entre ambos. Por ejemplo, si \emph{\ac{CC}} es 1, \emph{\ac{RMSE}}
debe ser 0, ya que todos los puntos se encuentran en la línea de la
función de regresión; cuanto más cercano sea el valor de \emph{\ac{CC}}
a 1 o -1, más próximos son los valores observados a la línea de predicción,
y por tanto menor será el error absoluto reflejado en \emph{\ac{RMSE}}. 

Por otro lado, complementariamente se utilizan indicadores relativos
en lugar de absolutos como los descriptos anteriormente, ya que ponderan
el error de predicción respecto a la variación estándar de las observaciones.
De esta manera se obtienen indicadores \emph{\ac{RAE}} y \emph{\ac{RRSE}}
de valores entre 0 y 1 para obtener una visión de las observaciones
respecto a la media. 


\subsection{Formato de los resultados\label{subsec:Formato-de-los}}

La herramienta devuelve como resultado un archivo en formato TXT almacenando,
por un lado, los valores resultantes de los parámetros fundamentales
de cada técnica y, por otro lado, la descripción del modelo construido.
La herramienta genera un archivo por cada técnica elegida por el usuario
para optimizar, en la dirección especificada en la configuración bajo
el nombre de la técnica. La figura \ref{fig:linear-regression-result}
permite una descripción gráfica de lo expresado anteriormente, donde
detalla A) los parámetros, B) Nombre del modelo y C) la función definida
para el atributo de predicción. 

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.55]{C:/Users/usuario/Tesisworkspace/Tesis_Standalone/tesis/images/linear-regression-result}
\par\end{centering}

\caption{Ejemplo de resultado del modelo \textquoteleft Linear Regression\textquoteright .
\label{fig:linear-regression-result}}
\end{figure}


La manera en que los datos son expuestos al usuario no representa
un formato compatible para cualquier herramienta sobre aprendizaje
de máquina, esto se debe a que no existe actualmente, un formato estándar
para almacenar los modelos, y esta discrepancia entre las herramientas
disponibles exige un seteo manual de las técnicas por cada evaluación
que se realice


\subsection{Parámetros de configuración de las técnicas\label{subsec:Par=0000E1metros-de-configuraci=0000F3nde}}

La optimización y posterior obtención de un modelo de calidad tiene
lugar a partir del establecimiento de diversos parámetros de configuración. 

Estos parámetros pueden requerir distintos valores adaptándose a condiciones
particulares de los datos que optimicen el resultado de la predicción.
Para brindar más detalle de estos parámetros, el Cuadro \ref{tab:Par=0000E1metros-de-configuraci=0000F3n}
presenta la lista completa de parámetros propios de cada técnica,
el valor por defecto adoptado para cada una y el rango de valores
establecido con el cual se determinará el mejor valor resultante. 

\begin{table}[H]
\begin{centering}
\includegraphics[scale=0.5]{C:/Users/usuario/Tesisworkspace/Tesis_Standalone/tesis/images/configuration-parameters}
\par\end{centering}

\caption{Parámetros de configuración de las técnicas de regresión \label{tab:Par=0000E1metros-de-configuraci=0000F3n}}
\end{table}


El proceso de optimización de las técnicas utiliza el rango de configuración
establecido para iterar en pasos tomando valores intermedios y evaluando
la calidad de la técnica con tales configuraciones, finalmente se
contrastan entre sí y se determina la mejor configuración para un
dataset y atributo a predecir particular. 

Los rangos para cada técnica se establecieron tras un análisis exhaustivo
de la influencia de estos valores sobre los datos. Los rangos de prueba
se definieron de manera aleatoria en conjunto de fundamentos teóricos
asociados a cada técnica, al mismo tiempo que el análisis de un rango
ya propuesto servía como base para definir uno nuevo. Los análisis
se llevaron a cabo sobre 20 archivos dataset dispuestos para esta
tesis. 

Por otro lado, los valores elegidos por defecto fueron tomados de
los valores propuestos por la herramienta Weka, a excepción del parámetro
\emph{Training Time} de la técnica \emph{MultiLayer Perceptron} que
fue reducido de 500 a 200 para mejorar la performance de tiempo del
algoritmo. 

Para el caso de la técnica \emph{Support Vector Machine} la configuración
es más compleja ya que involucra parámetros propios simples y un kernel
con parámetros específicos. Para la técnica \emph{\ac{SMO}}, el parámetro
\emph{gamma} y \emph{complexy} fueron analizados en conjunto con el
apoyo de fundamentos teoría y empíricas. La figura \ref{fig:RBF-parameters-SVM}
refleja el impacto que tienen los parámetros sobre la clasificación
de los datos. 

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.55]{C:/Users/usuario/Tesisworkspace/Tesis_Standalone/tesis/images/RBF-parameters-SVM}
\par\end{centering}

\caption{Efecto de los parámetros de la técnica SVM. \label{fig:RBF-parameters-SVM}}
\end{figure}


Las mejores opciones para configurar los parámetros se obtienen observando
la diagonal en donde los valores se incrementan a la par, la primer
imagen de la cuadrícula aplica una clasificación muy simple sobre
los datos, dejando en evidencia un alto grado de error en las predicciones.
La última imagen, en cambio, muestra un claro ejemplo de \emph{overfit},
por lo que no resulta ser una buena opción a la hora de buscar generalización.
La imagen central resulta entonces, ser la más apropiada para definir
los valores por defecto para estos parámetros. Por otro lado, la optimización
para el parámetro \emph{complexy} se determinó bajo el rango 0 - 25
debido a pruebas empíricas realizadas sobre el conjunto base de dataset. 

Respecto a la optimización del kernel, los cuatro algoritmos considerados
fueron analizados mediante la técnica prueba y error y de esa forma,
se determinaron los valores por defecto para los parámetros propios
de cada uno. Del análisis se desprenden algunas conclusiones consecuentes: 
\begin{description}
\item [{Normalized~Polynomial}] El valor por defecto para el parámetro
\emph{exponent} es 2.0 y hasta valores de 5.0 los resultados esperados
son buenos. 
\item [{Poly~Kernel}] El valor por defecto para el parámetro \emph{exponent}
es 1.0. Si el valor se incrementa se obtienen mejores resultados,
sin embargo para valores mayores a 5.0 el error de predicción comienza
a aumentar gradualmente. 
\item [{Puk}] El valor por defecto para el parámetro \emph{omega} es 1.0,
la modificación de este valor es indiferente a los resultados por
lo que no aplica a la optimización. Respecto a \emph{sigma} se adopta
el valor 0.01 ya que el incremento en este valor no produce buenos
resultados. 
\item [{RBF}] Partiendo de un valor \emph{gamma} de 0.01 se obtienen buenos
resultados, e incluso incrementando este valor a razón de 0.01 los
resultados tienden a mejorar. 
\end{description}

\subsection{Características de los dispositivos móviles usados\label{subsec:Caracter=0000EDsticas-de-los}}

En la mayoría de las pruebas se han utilizado dos dispositivos móviles
fundamentales, el modelo K3 Note de la marca Lenovo y el modelo Galaxy
S3 de la marca Samsung principalmente por las características del
procesador y memoria interna. El móvil lenovo es superior debido a
sus 8 núcleos de procesamiento frente a los 4 núcleos del Samsung
y a una memoria RAM con el doble de capacidad. 

También se utilizaron tres modelos más sólo para el escenario del
problema del viajante. Todas las especificaciones son expuestas en
el cuadro \ref{tab:Especificaciones-de-los}. 

\begin{table}[H]
\begin{centering}
\includegraphics{C:/Users/usuario/Tesisworkspace/Tesis_Standalone/tesis/images/used-mobiles}
\par\end{centering}

\caption{Especificaciones de los dispositivos móviles utilizados. \label{tab:Especificaciones-de-los}}
\end{table}



\section{Escenarios\label{sec:Escenarios}}

Definidas las métricas, la metodología de evaluación y los parámetros
de configuración, en la presente sección se detallarán los escenarios
o dominios estudiados a partir de una descripción detallada de los
dataset formados, cada uno de los componentes involucrados y los atributos
de entrada considerados formando un contexto particular para la predicción.
Por otro lado, se analizará el comportamiento o formato que adquieren
los datos sobre los atributos predichos para comprender el desempeño
de las diferentes técnicas sobre los mismos y la manera en que éstos
adecuan sus predicciones. 


\subsection{Escenario 1: Algoritmos para el problema del viajante\label{subsec:Escenario-1:-Algoritmos}}

En el campo de la teoría de complejidad computacional, el problema
del viajante o TSP por sus siglas en inglés, es tratado como un problema
NP-Completo y es modelado como un grafo de manera que las ciudades
son sus vértices, los caminos son las aristas y las distancias entre
caminos son los pesos de las aristas. Es un problema de minimización
tras la búsqueda de un recorrido completo que comienza y finaliza
en un vértice específico y visita el resto de los vértices exactamente
una vez con coste mínimo. Existen muchas variantes del problema, una
de ellas se trata del TSP simétrico en el cual la distancia entre
un par de ciudades es la misma en cada dirección formando un grafo
ponderado no dirigido. Esta variante fue la versión considerada por
la herramienta. 

Con el fin de garantizar instancias variadas del problema, (diferentes
cantidades de ciudades, distintas representaciones y pesos), se incorporó
a la herramienta una librería llamada TSPLib con múltiples archivos
de instancias del problema. La librería cuenta con 111 archivos de
formato TSP, y 32 archivos de formato OPT.TOUR que contienen el recorrido
óptimo del archivo que referencian. Los ejemplos oscilan desde 14
y hasta 18512 ciudades con un sólo ejemplo extremo de 85900, y utilizan
cuatro funciones de cálculo de la distancia entre ciudades: distancia
euclidiana, distancia geométrica, distancia pseudo euclidiana y función
techo. Para la obtención de las mediciones correspondientes, se realizó
una preselección de 32 archivos que comprenden ejemplos de entre 22
y 200 ciudades. Cabe destacar que fue necesaria la implementación
de un parser para el uso de los archivos.

Los dataset para este dominio han sido formados tras la ejecución
de seis algoritmos de resolución sobre 32 entradas del problema pertenecientes
a la librería TSPLIB dando lugar a un total de 192 instancias por
dataset; las pruebas fueron llevadas a cabo sobre el dispositivo móvil
Samsung Galaxy S4, y repetidas en los dispositivos S5 y S6, obteniendo
así, tres dataset análogos que incluyen como propiedades 7 atributos,
Id de operación, nombre de componente (algoritmo), entrada del problema
(nombre de archivo), exactitud y precisión en el resultado, tiempo
de respuesta y valor solución. Todos los dataset han sido almacenados
en archivos con formato \ac{CSV} bajo el nombre \textquoteleft 'Sx-results\textquoteright{}
según el modelo de dispositivo utilizado. Los componentes involucrados
incluyen el algoritmo del vecino más cercano, Programación Lineal,
Mejor ajuste, Kruskal, Prim, y el algoritmo de Transformación Local.
El algoritmo de Backtracking fue descartado de la lista debido al
gran consumo de memoria en los dispositivos imposibilitando el desarrollo
de las pruebas. 

En cuanto a la precisión y exactitud de las respuestas se consideraron
tres indicadores que toman en cuenta las repeticiones en la respuesta
y la totalidad o falta de los vértices incluidos. El indicador TP
(\emph{true positive}), para los vértices incluidos en la solución,
FP(\emph{false positive}), para las repeticiones de vértices y FN
(\emph{False Negative}) para los vértices no incorporados en la solución.
Por lo tanto, se consideró: 

\[
Precisi\acute{o}n=\frac{TP}{FP+TP}
\]


\[
Exactitud=\frac{TP}{FP+TP+FN}
\]


A modo de ejemplo, se presenta en la figura \ref{fig:TPS-graph-problem}
un grafo con comienzo en la ciudad A. Suponiendo que un algoritmo
de resolución arroja el siguiente camino solución: \{A, B, D, A\},
se obtiene una precisión del 100\% al tener un valor de \ac{TP} =
3 y un valor de \ac{FP} = 0 ya que no hay vértices repetidos en la
solución, sin embargo, la solución no es correcta ya que no incluye
la totalidad de vértices del conjunto (excluye al vértice C). En cambio,
al calcular la exactitud se obtiene un valor del 66\% al tener un
valor de \ac{TP} = 4, \ac{FP} = 1 y \ac{FN} = 1 brindando un concepto
más realista. 

El uso del indicador de precisión o el de exactitud dependerá del
contexto en el que se aplique. 

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.55]{C:/Users/usuario/Tesisworkspace/Tesis_Standalone/tesis/images/TPS-graph-problem}
\par\end{centering}

\caption{Ejemplo de grafo para el problema del viajante.\label{fig:TPS-graph-problem}}
\end{figure}


El objetivo de este escenario es la creación de modelos capaces de
predecir el tiempo de latencia de cada algoritmo de resolución frente
a distintas características de las entradas, y modelos para predecir
la precisión en los caminos retornados. En la figura \ref{fig:TPS-dataset-behaviour}
expuesta a continuación se muestra el comportamiento del conjunto
de datos de entrenamiento ejecutado en el dispositivo Samsung Galaxy
S4; ambos dataset restantes no son expuestos ya que presentan mínimas
diferencias. 

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.55]{C:/Users/usuario/Tesisworkspace/Tesis_Standalone/tesis/images/TPS-dataset-behaviour}
\par\end{centering}

\caption{Comportamiento del dataset para el escenario del problema del viajante.\label{fig:TPS-dataset-behaviour}}
\end{figure}


A primera vista la figura \ref{fig:TPS-dataset-behaviour} permite
observar una gran concentración de datos sobre los extremos para los
valores de precisión y tiempo de respuesta. En el primer caso, aproximadamente
un 94\% de los datos toman el valor 1, y en el segundo caso, un 88\%
de los datos toman valores entre 0 y 6.77 segundos. Este comportamiento
uniforme y poco distribuido de los datos obstaculiza el desarrollo
de un buen modelo predictivo. 

Respecto al atributo \emph{accuracy}, si bien presenta más dispersión
entre los datos, aproximadamente un 82\% circunda alrededor del valor
1 y un 15\% sobre valores cercanos a 0.008. 


\subsection{Escenario 2: Servicios para detección de rostros\label{subsec:Escenario-2:-Servicios}}

Hoy en día muchas soluciones para detección de rostro se proporcionan
como servicios Web, que aunque no son tan rápidos y usables sin conexión
a Internet como las bibliotecas de software, resultan generalmente
más precisos y proporcionan características muy peculiares del rostro.
Sin embargo, el rendimiento y la precisión de los servicios varían
según las propiedades de la imagen (tamaño, foco, oclusiones) y contexto
de ejecución (capacidad de la \ac{CPU}, conexión de red). Por lo
tanto el objetivo de este escenario es crear modelos para predecir
el tiempo de respuesta a partir de características variables de la
imagen de entrada y de los parámetros de configuración del componente
en cuestión.

Los dataset para este dominio han sido formados tras la ejecución
de diferentes componentes para detección de rostros en imágenes en
un único dispositivo móvil (Lenovo K3 Note), por tal motivo no se
incluyen en los archivos características propias del móvil ya que
significan valores constantes en la predicción. Los componentes involucrados
incluyen un servicio o proceso Android (Google Play Services (GMS)
face detector) y tres servicios Web (FaceRect API, Sky Biometry API
y Microsoft Face API). Estos cuatro componentes serán evaluados a
partir de subconjunto de 290 imágenes pertenecientes al dataset llamado
FDDB \cite{fddbTechReport} con características muy variadas. Cada
servicio es llamado especificando una imagen y un conjunto de parámetros
booleanos (a través del valor 0 y 1) que determinan las funciones
requeridas del algoritmo determinado. En los cuatro servicios, el
tiempo de respuesta es una variable continua y registrada en milisegundos. 

A continuación se detallan las principales características de los
servicios y los respectivos dataset creados para cada uno:


\paragraph{GMS}

La compañía Google ha implementado una colección extensa y variada
de aplicaciones para Android. Entre ellas, ofrece el paquete \textquoteleft com.google.android.gms.vision\textquoteright{}
el cual proporciona una funcionalidad común para trabajar con detectores
de objetos visuales. En la figura \ref{fig:GooglePlay-services}se
muestra la forma en que el objeto \emph{GoogleAPIClient} proporciona
una interfaz para conectar y hacer llamadas a cualquiera de los servicios
de Google Play disponibles tales como Google Play Games, Google Drive,
Google Maps, etc 

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.55]{C:/Users/usuario/Tesisworkspace/Tesis_Standalone/tesis/images/GooglePlay-services}
\par\end{centering}

\caption{Esquema conceptual para el uso de servicios de Google Play Services.\label{fig:GooglePlay-services}}


\end{figure}


El algoritmo permite setear tres parámetros diferentes (\emph{allLandmarks}
, \emph{allClassifications} , \emph{accurateMode}) dando lugar a 8
configuraciones posibles por imagen. Para el servicio GMS se utilizaron
290 imágenes originando un dataset de 2320 instancias. 

Archivo Dataset: \emph{ResponseTime - Google Play Service face detector.csv}.


\paragraph{FaceRect API y Sky Biometry API}

Los servicios web \emph{SkyBiometry} y \emph{FaceRect} son consumidos
directamente desde la aplicación online \emph{Mashape}, la cual ofrece
una gran variedad de aplicaciones, incluida una colección de Aplicaciones
sobre detección y reconocimiento de rostros. SkyBiometry y FaceRect
son aplicaciones que utilizan interfaz REST, es decir, los métodos
son llamados a través de internet usando los métodos \ac{HTTP} standard
como GET y POST a las direcciones correspondientes. Dependiendo de
los parámetros especificados en el request, el servidor puede generar
la respuesta tanto en formato JSON como \ac{XML}. Adicionalmente,
se utilizó el servicio GMS Visión de Google a partir de la librería
correspondiente. Los tres servicios son descritos en detalle en el
apéndice B.

El algoritmo de la aplicación FaceRect permite setear sólo una opción
(\emph{features}) por imagen, de modo que se construyó un dataset
con sólo dos propiedades, incluyendo el tiempo de respuesta y un total
de 54 instancias. 

Archivo Dataset: \emph{ResponseTime - FaceRect API.csv}. 

Por otro lado, el algoritmo de Sky Biometry permite setear siete parámetros
diferentes dando lugar a 128 configuraciones posibles por imagen (\emph{aggressive},
\emph{gender}, \emph{glasses}, \emph{smiling}, \emph{mood}, \emph{age},\emph{
eyes}). Para el servicio Sky Biometry se utilizaron 30 imágenes originando
un dataset de 3840 instancias y se incluyen 8 propiedades, además
de los parámetros configurables del tipo binario se añade el tiempo
de respuesta. 

Archivo Dataset: \emph{ResponseTime - SkyBiometry API.csv}. 


\paragraph{Microsoft Face API}

Face API es un servicio web en la nube que provee los algoritmos de
detección y reconocimiento de rostros más avanzados. El servicio es
consumido a través del sitio de Microsoft y las respuestas son retornadas
en formato JSON. El algoritmo permite setear seis propiedades (\emph{landmarks},
\emph{age}, \emph{gender}, \emph{facialHair}, \emph{smile} y \emph{headPos}).
El dataset está formado por 1826 instancias y siete propiedades, además
de los parámetros configurables como atributos binarios se incluye
el tiempo de respuesta. 

Archivo Dataset: \emph{ResponseTime - Microsoft Face API.csv}. 

En la figura \ref{fig:face-services-dataset-behaviour} que se muestra
a continuación se expone el comportamiento de los datos del atributo
\emph{Tiempo de respuesta} para cada uno de los servicios, en referencia
con la imagen A) FaceRect API, B) Microsoft Face API, C) Google Play
Service y D) Sky Biometry API. 

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.55]{C:/Users/usuario/Tesisworkspace/Tesis_Standalone/tesis/images/face-services-dataset-behaviour}
\par\end{centering}

\caption{Comportamiento del atributo \textquoteleft Tiempo de respuesta\textquoteright{}
de los servicios de detección de rostros.\label{fig:face-services-dataset-behaviour}}
\end{figure}


El servicio Sky Biometry presenta entre sus datos un 5\% de valores
infrecuentes y en esos casos valores extremos, siendo el único servicio
en presentar estas características. 

El servicio de Microsoft Face arrojó valores de tiempo de respuesta
uniformemente distribuidos en el intervalo tomando la forma de campana
de Gauss, los datos se distribuyen simétricamente sobre el intervalo,
es decir, no hay presencia de sesgos hacia la izquierda o hacia la
derecha. Google Play también tiene una distribución de Gauss con sesgo
hacia la izquierda. Puede observarse que presenta un intervalo muy
amplio, de modo que las propiedades configurables del algoritmo incrementan
considerablemente el tiempo de operación. Sin embargo, al contrastarlo
con el servicio de FaceRect, el mínimo de tiempo requerido por este
servicio es mucho mayor que el tiempo máximo arrojado por el de Google
Play, aún así cualquier análisis sobre el servicio FaceRect puede
ser precipitado, ya que se evaluó con un bajo número de instancias. 


\subsection{Escenario 3: Problema de la mochila\label{subsec:Escenario-3:-Problema}}

Al igual que el problema del agente viajero, el problema de la mochila
o \textquoteleft Knapsack problem\textquoteright{} por su nombre en
inglés, es un problema NP-Completo de optimización combinatoria, es
decir, se busca la mejor solución entre un conjunto finito de posibles
soluciones al problema. El problema simula la colocación de ítems
u objetos en una mochila de tal forma que se maximice el valor de
los ítems que contiene con la restricción de no superar el peso (o
volumen) máximo que puede soportar la mochila.

La evaluación de este dominio se llevó a cabo en dos modelos distintos
de dispositivos móviles (Samsung Galaxy S3 y Lenovo K3 Note) cuyo
objetivo es crear modelos de predicción del tiempo de respuesta y
la optimalidad del componente, es decir, la relación entre la solución
encontrada y la solución óptima retornando un valor entre cero y uno.
Para este dominio se implementaron dos algoritmos de resolución al
problema como componentes, el algoritmo greedy de complejidad O(n2
log(n)) y el algoritmo backtracking que encuentra la solución óptima
pero en tiempo exponencial O(2n). Ambos componentes fueron implementados
puramente en Java. Las instancias del problema se obtuvieron aleatoriamente
de las cuales se consideraron los siguientes atributos: 
\begin{lyxlist}{00.00.0000}
\item [{Primero~ID~de~Operación.}]~

\begin{lyxlist}{00.00.0000}
\item [{'KnapsackWeightRatio\textquoteright :}] teniendo en cuenta W como
el peso límite de la mochila y bi los pesos individuales de cada ítem,
se calcula bajo la fórmula $KWR=W/b_{1}+b_{2}+...+b_{n}$ arrojando
valores entre 0 y 1
\item [{Número}] de ítems en la mochila denotado como N. 
\item [{Tiempo}] de respuesta registrado en segundos. 
\end{lyxlist}
\item [{Segundo~Nombre~de~Componente.}]~

\begin{lyxlist}{00.00.0000}
\item [{Optimalidad}] o precisión de los componentes siempre medida respecto
a la solución brindada por el algoritmo Backtracking. 
\item [{Valor}] solución al problema. 
\end{lyxlist}
\end{lyxlist}
Respecto a las características propias del dispositivo de ejecución,
sólo se tomó en cuenta la frecuencia de CPU ya que ambos algoritmos
son single threads y corren en CPU, con la suposición que la frecuencia
de CPU incide sobre la predicción. 

Se formaron cuatro dataset para este escenario, dos por cada uno de
los dispositivos móviles evaluados. Bajo el nombre \emph{Optimality
and Response time - dispositivo XXX} se crearon datasets de 720 instancias
(360 para cada uno de los componentes) y siete propiedades como se
describieron anteriormente (Grupo A y B). Las entradas del problema
fueron consideradas desde un mínimo de 5 hasta un tamaño máximo de
24 ítems límite impuesto debido a la complejidad del algoritmo backtracking
y su correspondiente latencia exponencial. Por cada ítem se evaluaron
18 entradas al problema generadas aleatoriamente a partir de cuatro
valores: cantidad total de ítems, máximo valor y peso de un ítem,
y finalmente el peso o capacidad de la mochila. 

Por otro lado, bajo el nombre \emph{Response time - Greedy algorithm
- dispositivo XXX}, se crearon datasets de 4704 instancias y cuatro
propiedades (Grupo A) con entradas del problema de tamaño mínimo de
5 ítems, e incrementalmente hasta un máximo de 200, con 24 entradas
dedicadas a cada número de ítem generadas también aleatoriamente.
A continuación en lafigura \ref{fig:Knapsack-dataset-behaviour} se
muestra el comportamiento de los datos del atributo \emph{Tiempo de
respuesta}, en referencia a la imagen, A) \textquoteleft Opt \& Resp
Lenovo K3\textquoteright , B) \textquoteleft Opt \& Resp Samsung Galaxy
S3\textquoteright , C) Greedy Lenovo K3 y D) Greedy Samsung S3. 

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.55]{C:/Users/usuario/Tesisworkspace/Tesis_Standalone/tesis/images/Knapsack-dataset-behaviour}
\par\end{centering}

\caption{Comportamiento del atributo \textquoteleft Tiempo de respuesta\textquoteright{}
para el problema de la mochila. \label{fig:Knapsack-dataset-behaviour}}
\end{figure}


En la ejecución de los algoritmos de Backtracking y Greedy en ambos
dispositivos (Imagen A y B) se observa una concentración aproximada
del 93\% de los datos en un intervalo muy pequeño y un 5\% de los
datos se encuentran en el intervalo mayor a 1 segundo, por lo cual
podría concluirse que son valores atípicos o poco frecuentes. Este
comportamiento muy homogéneo de los datos, dificultará la construcción
de un modelo predictivo de alta calidad. Por otro lado, los dataset
que incluyen al algoritmo Greedy, presentan más dispersión de los
datos cuya distribución toma forma exponencial (Imagen C) y forma
de campana de Gauss con sesgo hacia la izquierda (Imagen D). La heterogeneidad
en los datos puede posibilitar la construcción de un buen modelo.
Respecto al análisis de los valores registrados, se puede observar
que las mismas pruebas ejecutadas en el dispositivo Samsung Galaxy
S3 consumen notoriamente más tiempo de operación.

Por otro lado, se expone también en la figura \ref{fig:Knapsack-optimi-dataset-behaviour}
el comportamiento para el atributo optimalidad de los dataset que
incluyen ambos algoritmos. (Backtracking y Greedy). 

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.55]{C:/Users/usuario/Tesisworkspace/Tesis_Standalone/tesis/images/Knapsack-optimi-dataset-behaviour}
\par\end{centering}

\caption{Comportamiento del atributo \textquoteleft Optimalidad\textquoteright{}
para el problema de la mochila \label{fig:Knapsack-optimi-dataset-behaviour}}
\end{figure}


Las pruebas ejecutadas en el modelo K3 de Lenovo arrojaron valores
de optimalidad muy altos, un 80\% de los datos con optimalidad del
100\%, y menos del 5\% del total adquiere valores por debajo de 0.95.
Esta cifra incluye valores extremos que representan el 1\% de la totalidad
de observaciones. Por lo tanto, la solución brindada por el algoritmo
Greedy es generalmente óptima. Por otro lado, las pruebas ejecutadas
en el dispositivo Samsung Galaxy arrojaron un grado de optimalidad
del 69\%, y sólo un 12\% de los datos corresponden a valores entre
0.9 y 1.0, sin incluir este último. Se presume que el dataset presenta
algunas anomalías ya que un 10\% de los datos tienen valores superiores
a 1.0, contraponiendo el concepto de optimalidad. 


\subsection{Escenario 4: Multiplicación de matrices\label{subsec:Escenario-4:-Multiplicaci=0000F3n}}

El producto de matrices corresponde a problemas de clase P ya que
a diferencia de los problemas NP, su complejidad es polinómica. El
producto entre matrices no es conmutativo, depende del orden de las
matrices intervinientes y su multiplicación sólo es posible si el
número de filas de la primera matriz es igual al número de columnas
de la segunda. 

Los dataset para este dominio han sido formados tras la ejecución
de diferentes algoritmos de multiplicación de matrices, con tamaños
variados de matrices sobre 2 modelos de dispositivos móviles, Lenovo
K3 y Samsung Galaxy S3. Lo interesante de este dataset, es que los
algoritmos fueron implementados con diferentes librerías y diseñados
para ser ejecutados por diferente elementos de hardware (\ac{CPU},
\ac{GPU}, etc). 

Los componentes o algoritmos considerados para este dominio se describen
a continuación: 
\begin{description}
\item [{Matrix~Multiplication}] implementación simple desarrollada puramente
en lenguaje Java. 
\item [{Matrix~Multiplication~Multi~Thread}] corresponde a la misma
versión del componente anterior paralelizada en ocho threads de ejecución. 
\item [{Matrix~Multiplication~Render~Script}] es una versión implementada
con RenderScript , de modo que si el dispositivo tiene un \ac{GPU}
compatible con RenderScript, éste lo ejecutará. Por tal razón el tiempo
de operación es mucho más rápida. 
\item [{Native~Matrix~Multiplication}] es una versión que usa \ac{JNI}
para que la multiplicación se realice sobre código nativo desarrollado
en lenguaje C++, el cual se compila específicamente según cada arquitectura
de \ac{CPU} (Armeabi, x86, etc). 
\item [{Matrix~Multiplication~with~Eigen}] versión que usa \ac{JNI}
para ejecutar la multiplicación de matrices provista por la librería
nativa Eigen. 
\item [{Matrix~Multiplication~with~OpenCV}] versión que usa \ac{JNI}
para ejecutar la multiplicación a través de la librería OpenCV . 
\end{description}
Las entradas del problema utilizadas para la evaluación fueron generadas
aleatoriamente a partir de las dimensiones (tamaño) de las matrices
involucradas a partir del número de filas y columnas de la primer
matriz denominada matriz A y el número de columnas de la segunda matriz
denominada matriz B, esta distinción es importante teniendo en cuenta
la propiedad de no conmutatividad del producto de matrices. Adicionalmente,
ambas matrices pueden ser configuradas externamente. De cada problema,
las propiedades que se tomaron en cuenta fueron: el número de columnas
de la primer matriz (\emph{AColumn}), el número de filas y el de columnas
de la segunda matriz (\emph{ARow} y \emph{BColumn}), la complejidad
temporal de la operación definida como O(AColumn x ARow x BColumn),
el nombre del componente y el tiempo de respuesta de la operación
registrada en segundos. No fueron incluidos atributos relativos al
dispositivo de ejecución, sin embargo podrían considerarse propiedades
como número de cores de \ac{CPU}, cores de \ac{GPU}, frecuencia,
etc. ya que se piensa son buenos predictores de tiempo para algunos
algoritmos. Los dataset bajo el nombre \emph{Response time NxNxN -
Samsung Galaxy S3} y \emph{Response time NxNxN - Lenovo K3 Note} se
componen de 894 instancias lo cual comprende un total de 149 entradas
por cada uno de los seis componentes. Por otro lado, los dataset bajo
el nombre de \emph{Response time NxMxL - Sin RenderScript component
- Samsung Galaxy S3} y \emph{Response time NxMxL - Sin RenderScript
component - Lenovo K3 Note} excluyen, la versión implementada con
RenderScript y comprenden 745 instancias. 

A continuación en la figura \ref{fig:matrix-dataset-behaviour} se
muestra el comportamiento del atributo \emph{Tiempo de respuesta}
de los dataset formados para este dominio, en referencia a la imagen,
A) Sin componente RenderScript en Lenovo K3, B) Sin componente RenderScript
en Samsung Galaxy S3, C) Todos los componentes en Lenovo K3 y D) Todos
los componentes en Samsung Galaxy S3.

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.55]{C:/Users/usuario/Tesisworkspace/Tesis_Standalone/tesis/images/matrix-dataset-behaviour}
\par\end{centering}

\caption{Comportamiento del atributo \textquoteleft Tiempo de respuesta\textquoteright{}
para el problema de la multiplicación de matrices.\label{fig:matrix-dataset-behaviour}}
\end{figure}


En todos los casos puede observarse una distribución exponencial de
los datos incluyendo valores extremos o infrecuentes. Respecto a los
valores de tiempo registrados, puede notarse a simple vista que las
pruebas ejecutadas en el dispositivo Lenovo K3 consumen menor tiempo
en contraste con el dispositivo Samsung Galaxy S3. 

Lo interesante de este escenario es que permite la creación de modelos
simples, por ejemplo, a partir de la técnica Linear Regression que
arroje los mismos o mejores resultados que otras técnicas más complejas
ya que entre los términos de la función de predicción se expresa la
complejidad del algoritmo de matrices. Incluso, se podrían usar técnicas
específicas para cada componentes evaluando y analizando el impacto
sobre la predicción. Por ejemplo, para el componente \emph{Multiplicación
MultiThread} en la técnica Linear Regression puede considerarse el
número de threads; para el componente con RenderScript puede considerarse
alguna característica propia del \ac{GPU} donde se ejecuta si implica
alguna mejora en los resultados predictivos. 


\section{Resultados y discusión\label{sec:Resultados-y-discusi=0000F3n}}

En esta sección final de la evaluación se agrupan los resultados para
contrastar los escenarios entre sí con el fin de determinar relaciones
entre las técnicas, el contexto o dominio en el que se aplican y el
desempeño sobre los atributos que predicen, esto es, si la técnica
se ajusta más adecuadamente a un tipo de atributo o a otro, a modo
de inferir las conclusiones pertinentes. Además, se analizan detalles
sobre la performance del proceso de optimización de las técnicas respecto
al tiempo de cómputo que insumen y su relación con el tamaño del dataset
que procesa. 


\subsection{Resultados para el problema del viajante.\label{subsec:Resultados-para-el}}

\begin{table}[H]
\begin{centering}
\includegraphics[bb=0bp 0bp 596bp 619bp,scale=0.55]{C:/Users/usuario/Tesisworkspace/Tesis_Standalone/tesis/images/response-TSP}
\par\end{centering}

\caption{Resultados del atributo Tiempo de respuesta para el escenario \textquoteleft problema
del viajante\textquoteright .\label{tab:Resultados-del-atributo}}
\end{table}


A partir de la figura \ref{tab:Resultados-del-atributo} se desprenden
las conclusiones con respecto al primer escenario. Como primer punto
tanto el modelo de \emph{MultiLayer Perceptron} como el de \ac{SVM}
son, claramente, los mejores en cuanto a adaptación al modelo. Ambos
presentan una correlación con los datos de 1 (\emph{CC}), lo que representa
la exactitud de los datos calculado con respecto a los reales. Como
ya se explicó en la sección\ref{subsec:Ajuste-del-modelo:}, esto
puede parecernos lo más óptimo, pero observando las métricas y las
curvas de errores, ambos modelos presentan un problema de overfitting. 

Teniendo esto en cuenta, se descartan ambos como los mejores modelos
para este tipo de problema. A su vez, se descarta el \emph{K-mean
Clusterer }ya que los niveles de correlación son los mas bajos y los
errores los más altos.

En todos los escenarios presentados, se optó por el caso intermedio
de adaptación, considerando que el mismo es el mejor obtenido evitando
casos de overfitting o underfitting. Este se escogió teniendo en cuenta
los valores de CC intermedios, con un error MAE aceptable considerando
los valores propios y errores promedios bajos. Así, en este caso,
el más eficiente es el \emph{Linear Regression. }A continuación, se
presenta el comportamiento de este último con respecto a los valores
de referencia.

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.55]{C:/Users/usuario/Tesisworkspace/Tesis_Standalone/tesis/images/linear-regression-behaviour.PNG}
\par\end{centering}

\caption{Lineas de predicción en la herramienta Nekonata}
\end{figure}


Con el mismo método de analisis se analizó el dataset TSPlib.csv considerando
la precisión del algoritmo.

\begin{table}[H]
\begin{centering}
\includegraphics[bb=0bp 0bp 596bp 619bp,scale=0.55]{C:/Users/usuario/Tesisworkspace/Tesis_Standalone/tesis/images/precision-TPS}
\par\end{centering}

\caption{Resultados del atributo precisión para el escenario \textquoteleft problema
del viajante\textquoteright .}
\end{table}


Así, se puede apreciar que los que presentan una mejor adaptación
en este caso siguen siendo el \ac{MLP} y el \ac{SMO}. Aun así, considerando
el analisis antes hecho, esta vez el mejor aloritmo es el \ac{SGD}. 

Si tenemos en cuenta lo visto en la sección \ref{subsec:Regresi=0000F3n-Lineal},
el mejor algoritmo teórico que mejor se adapta a el problem del viajante
es el \emph{LinearRegression }es sus dos implementaciones (Ridge y
SGD). 

\begin{figure}[H]


\begin{centering}
\includegraphics[scale=0.55]{C:/Users/usuario/Tesisworkspace/Tesis_Standalone/tesis/images/errors-comparison-response-S5}
\par\end{centering}

\caption{Figura comparativa de las dos implementaciones de regresión lineal
para el problema del vaiajante}


\end{figure}



\subsection{Resultados para los servicios de detección de rostros.}

Durante el proceso de formación de los dataset, se consideró en primer
medida, la incorporación de variables sobre la imagen, como el tamaño,
la intensidad de color, entre otras. Sin embargo, fueron descartadas
en la versión final ya que no demostraron influir sobre la precisión
y el tiempo de respuesta al alcanzar un grado de correlación por debajo
de 0.05 entre las variables de la imagen y las variables a predecir.
Sólo los parámetros de configuración con los que se invocan a la función
de detección de cada componente afectaron directamente al tiempo de
respuesta requerido por el servicio. Los resultados de los modelos
obtenidos para la predicción del atributo \emph{Tiempo de respuesta}
se exponen en el cuadro \ref{tab:Resultados-response-face}

<Añadir conclusiones>

\begin{table}[H]
\begin{centering}
\includegraphics[bb=0bp 0bp 596bp 619bp,scale=0.55]{C:/Users/usuario/Tesisworkspace/Tesis_Standalone/tesis/images/response-face}
\par\end{centering}

\caption{Resultados del atributo \textquoteleft Tiempo de respuesta\textquoteright{}
para los servicios de detección de rostros.\label{tab:Resultados-response-face}}
\end{table}



\subsection{Resultados para el problema de la mochila.}

<Añadir conclusiones >

\begin{table}[H]
\begin{centering}
\includegraphics[bb=0bp 0bp 596bp 619bp,scale=0.55]{C:/Users/usuario/Tesisworkspace/Tesis_Standalone/tesis/images/response-knapsack}
\par\end{centering}

\caption{Resultados del atributo Tiempo de respuesta para el escenario \textquoteleft problema
de la mochila\textquoteright . }
\end{table}


\begin{table}[H]
\begin{centering}
\includegraphics[bb=0bp 0bp 596bp 619bp,scale=0.55]{C:/Users/usuario/Tesisworkspace/Tesis_Standalone/tesis/images/precision-knapsack}
\par\end{centering}

\caption{Resultados del atributo precisión para el escenario \textquoteleft problema
de la mochila\textquoteright . }
\end{table}



\subsection{Resultados para el problema de la multiplicación de matrices.}

<Añadir conclusiones>

\begin{table}[H]
\begin{centering}
\includegraphics[bb=0bp 0bp 596bp 619bp,scale=0.55]{C:/Users/usuario/Tesisworkspace/Tesis_Standalone/tesis/images/reponse-matrix}
\par\end{centering}

\caption{Resultados del escenario \textquoteleft Multiplicación de matrices\textquoteright{}}
\end{table}



\section{Conclusiones \label{sec:Conclusiones}}
\end{document}
